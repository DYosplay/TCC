PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono051 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 1111 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono052 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 2222 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono053 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 3333 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono054 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 4444 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono055 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 5555 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono056 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 6666 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono057 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 6666 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono058 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 7777 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono059 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 8888 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=25 -t=ds_mono060 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 9999 -z