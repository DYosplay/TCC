PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test456 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0006
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test457 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0005
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test458 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0004
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test459 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0003
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test460 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0002
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=1 python run_ds_transformer.py -ep=12 -t=ds_test461 -lr 0.01 -bs 32 -lt=triplet_mmd -a 1.0 -tm 1.0 -p 0.9 -q 0.1 -qm 1.5 -dc 0.6 -nlr 0.0001