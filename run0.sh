PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono21 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 333 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono22 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 888 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono23 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 6666 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono24 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 9999 -z

PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono25 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 333 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono26 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 888 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono27 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 6666 -z
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono28 -lr 0.01 -bs 32 -lt=triplet_loss -dc 0.9 -stop 26 -seed 9999 -z