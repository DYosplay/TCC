PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono12 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 333
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono14 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 888
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono15 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 6666
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono16 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 9999

PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono17 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 333
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono18 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 888
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono19 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 6666
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 CUDA_VISIBLE_DEVICES=0 python run_ds_transformer.py -ep=25 -t=ds_mono20 -lr 0.01 -bs 32 -lt=triplet_mmd -dc 0.9 -stop 26 -seed 9999